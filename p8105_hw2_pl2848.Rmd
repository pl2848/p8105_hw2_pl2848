---
title: "p8105_hw2_pl2848"
author: "Pei Liu"
date: "2022-10-01"
output: github_document
---

Load the libraries we need:
```{r}
library(tidyverse)
library(readxl)
```

Problem 1

Read the data and clean column names. Retain line, station, name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance. Convert the entry variable from character (YES vs NO) to a logical variable (the ifelse or recode function may be useful).
```{r}
transit_df = read_csv(
  "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
  col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% 
  janitor::clean_names() %>% 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))

transit_df

```



# Questions:
How many distinct stations are there? Note that stations are identified both by name and by line (e.g. 125th St 8th Avenue; 125st Broadway; 125st Lenox); the distinct function may be useful here.

Answer: 465
```{r}
nrow(distinct(transit_df, line, station_name))
```


How many stations are ADA compliant?

Answer: 84
```{r}
unique_station_ada = transit_df %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
unique_station_ada
```


What proportion of station entrances / exits without vending allow entrance?

37.7%

```{r}
filter(transit_df, vending == "NO") %>% 
  pull(entry) %>% 
  mean
```


Reformat data so that route number and route name are distinct variables. How many distinct stations serve the A train? Of the stations that serve the A train, how many are ADA compliant?

Answer: Number of distinct stations serve the A train is 60. And 17 of them are ADA complicant.

```{r}
transit_df %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct

transit_df %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```
```{r}
num_station_a = transit_reformat %>% 
  filter(route_name == "A") %>% 
  nrow()

num_station_a

num_ada_com = transit_reformat %>% 
  filter(route_name == "A", ada == TRUE) %>% 
  nrow()
num_ada_com
```


# Problem 2
Read and clean the Mr. Trash Wheel sheet:

specify the sheet in the Excel file and to omit non-data entries (rows with notes / figures; columns containing notes) using arguments in read_excel

use reasonable variable names, omit rows that do not include dumpster-specific data, round the number of sports balls to the nearest integer and converts the result to an integer variable (using as.integer)
```{r}
mr_trash_wheel = read_excel("./data/Trash Wheel Collection Data.xlsx", sheet = 1, skip = 1, range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(sports_balls = as.integer(round(sports_balls,
                                         digits = 0)),
         dumpster = as.numeric(dumpster),
         year = as.numeric(year))
         
mr_trash_wheel

# Discription: Therea are 547 observations and 14 variables  in mr_trash_wheel dataset. The key variables include: dumpster, month, year, date, weight (tons), column_cubic_yards, and 8 trash types. 

# I read the first sheet, skip first line (it is picture), and select the range of columns I want to read. I then cleaned the names, drop dumpter na, and change the type of dumpster as numeric, and rounded the sport balls variables to nearest in integer.
```
Use a similar process to import, clean, and organize the data for Professor Trash Wheel
```{r}
professor_trash_wheel = read_excel("./data/Trash Wheel Collection Data.xlsx", sheet = 2, skip = 1, range = cell_cols("A:M")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(dumpster = as.numeric(dumpster))

professor_trash_wheel

# Description: There are 94 observations in total, and 13 variables in the professor_trash_wheel dataset. The key variables include: dumpster, month, year, date, weight (tons), column_cubic_yards, and 7 trash types. 

# I read the second sheet, skip first line (it is picture), and select the range of columns I want to read. I then cleaned the names, drop dumpter na, and change the type of dumpster as numberic. I also changed year to numeric variable.
```
add an additional variable to both datasets before combining.
```{r}
mr_trash_wheel = mutate(mr_trash_wheel, trash_wheel_name = "Mr. Trash")
professor_trash_wheel = mutate(professor_trash_wheel, trash_wheel_name = "Professor")

# I added one column for each trash wheel dataset, for the convience of joining them.


```

combine this with the Mr. Trash Wheel dataset to produce a single tidy dataset
```{r}
combine_trash_wheel = full_join(mr_trash_wheel, professor_trash_wheel)
combine_trash_wheel

# Description of the joined dataset:
# There are 641 observations and 15 variables in combine_trash_wheel. The key variables include: dumpster, month, year, date, and many trash types.
# I joined the dataset by full_join.
```






what was the total weight of trash collected by Professor Trash Wheel?

Answer: 190.12 tons
```{r}
# I sum the weigh_tons of professor trash wheel dataset
sum_weight = sum(professor_trash_wheel$weight_tons)

sum_weight
```

What was the total number of sports balls collected by Mr. Trash Wheel in 2020?

Answer: 856

```{r}
# I first filter the mr_trash_wheel in year 2020, and then sum sports_balls 
mr_trash_wheel_2020 = filter(mr_trash_wheel, year == 2020)
num_sport_balls_2020 =  sum(mr_trash_wheel_2020$sports_balls)
num_sport_balls_2020
```

# Problem 3
First, clean the data in pols-month.csv. Use separate() to break up the variable mon into integer variables year, month, and day; replace month number with month name; create a president variable taking values gop and dem, and remove prez_dem and prez_gop; and remove the day variable.
```{r}
pols_month = read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names() %>%
  separate(mon, into = c("year", "month", "day")) %>% 
  mutate(month = month.abb[as.numeric(month)],
         year = as.numeric(year),
         day = as.numeric(day)) %>% 
  pivot_longer(starts_with("prez"),
               names_to = "president",
               names_prefix = "prez_",
               values_to = "party" ,
               values_drop_na = TRUE) %>% 
  filter(party != 0) %>% 
  select(-party, -day)
pols_month

# This data set has 822 observations, and 9 variables. Year from 1947-2015. It contains year, month and number of national politicians who are democratic or republican at any given time
```

Second, clean the data in snp.csv using a similar process to the above. For consistency across datasets, arrange according to year and month, and organize so that year and month are the leading columns.
```{r}
library(lubridate)
```



```{r}
snp = read_csv("./data/fivethirtyeight_datasets/snp.csv") %>% 
  janitor::clean_names()  %>% 
  mutate(date = mdy(date)) %>% #%>% 
  separate(date, into=c("year", "month", "day")) %>% 
  mutate(year = ifelse(as.numeric(year) <= 2022,
                    as.numeric(year),
                    as.numeric(year)-100),
         month = month.abb[as.numeric(month)])  %>% 
  arrange(year, month)

snp

# This data set has 787 observations and 4 columns. Year from 1950- 2015. It contains variables year, month, day and close. Close means the closing values of the S&P stock index on the associated date.
```




Third, tidy the unemployment data so that it can be merged with the previous datasets. This process will involve switching from “wide” to “long” format; ensuring that key variables have the same name; and ensuring that key variables take the same values.
```{r}
unemployment = read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>% 
  janitor::clean_names() %>% 
  drop_na() %>% 
  pivot_longer(jan:dec,
               names_to = "month",
               values_to = "unemployment_rate",
               values_drop_na = TRUE) %>% 
  mutate(month = str_to_title(month))

unemployment

# This dataset has 810 observations and 3 variables.Year from 1948-2015. The key variables are year, month and unemployment_rate. It is mainly about the unemployment rate
```


Join the datasets by merging snp into pols, and merging unemployment into the result.
```{r}
join_pols_snp = right_join(pols_month, snp) 
join_final = merge(join_p3,unemployment)
join_final

# This dataset has 780 observations and 12 columns. Year from 1950-2015. The key variables includes year, president, close, unemployment_rate. This table merges information from pols_months, snp and unemployment.
```

